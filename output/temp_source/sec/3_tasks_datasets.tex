\section{TimePerceptBench: Tasks and Datasets}

TimePerceptBench provides a comprehensive evaluation framework for temporal understanding capabilities in multimodal large language models through two complementary tasks that capture fundamental aspects of temporal reasoning. Our benchmark design leverages remote sensing imagery to provide objective temporal ground truth while systematically assessing model performance across multiple temporal scales and complexity levels. These tasks are specifically designed to isolate different aspects of temporal cognition, enabling fine-grained analysis of model capabilities and limitations.

\subsection{Task Overview}

Drawing inspiration from human temporal perception, we decompose temporal understanding into two core capabilities that reflect different cognitive processes involved in temporal reasoning. Temporal Order Understanding (TOU) evaluates the ability to comprehend chronological sequences and identify temporal relationships within multi-image sequences, representing the directional aspect of temporal cognition. Temporal Interval Understanding (TIU) evaluates the ability to comprehend time spans and identify temporal interval relationships between image pairs, representing the quantitative dimension of temporal understanding---analogous to how vectors possess both direction and magnitude. The multiple subtasks under these two tasks enable comprehensive evaluation while allowing for more systematic analysis of different temporal understanding mechanisms.

\subsection{Temporal Order Understanding (TOU)}

The Temporal Order Understanding task evaluates models' ability to comprehend chronological sequences and identify temporal relationships within multi-image sequences. This task addresses a fundamental aspect of temporal cognition---understanding how events unfold over time and their sequential relationships. Our TOU task is constructed using the Satellite Images Time Series Change Caption (SITSCC) dataset, which contains 1,000 groups of remote sensing image sequences. Each group captures the same geographical location across multiple time points, with each sequence containing an average of 5 or more images, covering various temporal scales from seasonal changes to multi-year urban development. We randomly partition the dataset into 800 groups for training and 200 groups for evaluation.

The TOU task encompasses five complementary subtasks at different granularities and difficulty levels, evaluating distinct aspects of temporal sequence understanding:

\begin{enumerate}
    \item \textbf{Temporal Anomaly Localization (TAL)} presents models with a sequence of five images where four images from the same location form a coherent temporal progression, while one anomalous image either exhibits temporal inconsistency or originates from a different location, disrupting the evolutionary logic. Given a sequence where one image is anomalous, the model can readily identify its temporal position through conspicuous visual patterns and inconsistencies in temporal evolution, outputting its temporal index. This task primarily evaluates the model's ability to recognize the positional identification of specific time points within a sequence.
    
    \item \textbf{Image Sequence Reordering (ISR)} presents models with shuffled image sequences and requires them to predict the correct temporal ordering. Given an image sequence with true temporal order, the model receives a shuffled version and must predict an ordering that approximates the ground truth order. This task evaluates the model's ability to understand temporal structure and sequential evolution patterns across time periods.
    
    \item \textbf{Sequential Order Verification (SOV)} assesses whether models can distinguish between temporally consistent and inconsistent image sequences. Given an image sequence, the order may be temporally consistent (e.g., chronological) or shuffled. Models are presented with both correctly ordered sequences and shuffled sequences, requiring them to determine whether the sequence represents a reasonable temporal evolution process, outputting True or False. This binary classification task tests the model's sensitivity to temporal inconsistencies.
    
    \item \textbf{Pairwise Order Verification (POV)} is a simplified version of SOV, focusing on local temporal relationships by presenting image pairs and requiring models to determine their temporal order. Given an image pair where the true temporal order satisfies chronological progression, the model must judge whether the temporal sequence presented by these two images is reasonable, outputting True or False. This task evaluates the model's ability to identify direct temporal relationships and understand subtle temporal transitions between adjacent time points.
    
    \item \textbf{Temporal Position Localization (TPL)} evaluates the model's ability to infer missing temporal positions within a structured sequence. Models are presented with four images: the first three images correspond to positions 1, 3, and 5 in a complete, evenly spaced temporal sequence, while the fourth image represents a missing time point. This task is a simplified version of ISR, where the model does not need to consider all positions for all images, but only needs to assess the matching degree between one image and two possible position orderings.
\end{enumerate}

The TOU task provides comprehensive evaluation of temporal sequence understanding capabilities across multiple difficulty levels and reasoning granularities.

\subsection{Temporal Interval Understanding (TIU)}

The Temporal Interval Understanding task evaluates the ability to comprehend time spans and identify temporal interval relationships between image pairs. This task addresses the quantitative aspect of temporal reasoning. Our TIU task utilizes the fMoW dataset, which contains over one million images from more than 200 countries with detailed metadata including precise timestamps. We select representative categories including airport\_hangar, airport\_terminal, factory\_or\_powerplant, and other infrastructure types that exhibit temporal evolution patterns. From each category, we extract image sequences from the same geographical locations, generating over 30,000 image pairs spanning different temporal scales, while filtering out image groups potentially affected by cloud cover or other interference based on their metadata. During the sample construction process, to avoid bias in model learning caused by uneven category distribution, we further filter and resample based on change detection results, ensuring that each TIU subtask has 800 groups for training and 200 groups for evaluation.

The TIU task encompasses four complementary subtasks at different granularities and difficulty levels, evaluating distinct aspects of temporal interval understanding:

\begin{enumerate}
    \item \textbf{Interval Category Estimation (ICE)} evaluates the model's ability to estimate absolute temporal durations for image pairs. Given two images of the same location taken at times $t_1$ and $t_2$, the model must classify the time span $\Delta t = |t_2 - t_1|$ into one of five categories: A. Days (1--30 days), B. 1--3 Months (31--90 days), C. 3--12 Months (91--365 days), D. 1--2 Years (366--730 days), or E. 2+ Years (731 days or more). This task evaluates the model's ability to perceive temporal magnitude from visual changes and map observed variations to discrete temporal categories.
    
    \item \textbf{Pairwise Interval Comparison (PIC)} focuses on relative temporal interval judgment by presenting two image pairs from the same location at different times. Given four images corresponding to times $t_1, t_2, t_3, t_4$, where $(t_1, t_2)$ are from the same location and $(t_3, t_4)$ are from another location, the model must determine whether $|t_2 - t_1|$ is larger than $|t_4 - t_3|$, outputting True or False. This task evaluates the model's ability to compare temporal intervals without requiring absolute quantification, mitigating the challenge that absolute time is difficult to judge in remote sensing imagery.
    
    \item \textbf{Interval-based Pair Ranking (IPR)} extends PIC by requiring models to rank three image pairs by their temporal spans. Given three groups of image pairs A, B, and C, where each group shows the same location at different times, the model must rank these groups from shortest to longest time span. This task evaluates the model's ability to establish a global temporal ordering across multiple independent span observations, requiring simultaneous comparison and consistent ranking.
    
    \item \textbf{Extremum Interval Identification (EII)} is a simplified version of IPR, assessing the model's ability to identify extreme temporal intervals among multiple options. Given four groups of image pairs---Group A through Group D---where each pair shows the same location at different times, the model only needs to identify which group has the longest time span without ranking all groups by their temporal spans.
\end{enumerate}

The TIU task provides comprehensive evaluation of temporal interval understanding capabilities across absolute and relative temporal reasoning paradigms.

\subsection{Evaluation Metrics and Protocols}

Our evaluation framework employs task-specific metrics designed to capture different aspects of temporal understanding. For the reordering task under TOU, we utilize the Positive-Negative Ratio (PNR) as the primary evaluation metric, while for other binary judgment or classification tasks, we use accuracy as the evaluation metric, similar to the approach taken for TIU. The PNR metric can measure the stability and consistency of models in local temporal order judgment. Given an image sequence $S$ with true temporal order $O_{\text{true}}$ and model-predicted ordering $O_{\text{pred}}$, for any two images $i, j$ in the same sequence, if they satisfy the same magnitude relationship in both the predicted ordering and true ordering, i.e., $(O_{\text{pred}}(i) - O_{\text{pred}}(j))(O_{\text{true}}(i) - O_{\text{true}}(j)) > 0$, then this sample is recorded as a positive pair (Positive); if this product is negative, it is recorded as a negative pair (Negative).

The Positive-Negative Ratio is defined as follows:
\begin{equation}
    \text{PNR} = \frac{N_{\text{positive}}}{N_{\text{negative}}},
\end{equation}
where $N_{\text{positive}}$ and $N_{\text{negative}}$ represent the number of image pairs in the sequence that satisfy positive and negative order relationships, respectively.

The PNR metric exhibits higher robustness and interpretability compared to ``full sequence accuracy.'' Unlike full sequence accuracy, which ignores potential local consistency in ordering, PNR provides more detailed measurement of model performance in order understanding by statistically analyzing the relative order relationships between all image pairs. This makes it particularly suitable for boundary cases in remote sensing imagery where visual ambiguity and unclear ordering may exist.

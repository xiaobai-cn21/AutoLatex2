\begin{abstract}
Temporal understanding represents a fundamental cognitive capability that remains limited in current multimodal large language models (MLLMs). While existing benchmarks primarily focus on static visual understanding or simple sequential patterns, they fail to adequately evaluate comprehensive temporal reasoning across extended sequences with objective ground truth. To address these limitations, we introduce TimePerceptBench, a comprehensive benchmark using timestamped remote sensing imagery with sparse temporal sampling (days to years). We explicitly distinguish two complementary capabilities: Temporal Order Understanding (TOU)---determining event sequences through 5 tasks, and Temporal Interval Understanding (TIU)---quantifying time intervals through 4 tasks, evaluated on 1,000+ multi-image groups. We evaluate 6 state-of-the-art MLLMs including GPT-4o mini and 5 open-source models. Unfine-tuned models show limited temporal reasoning: reordering achieves Positive-Negative Ratio (PNR) around 1.0--1.8, while TIU tasks perform near random baselines (interval category estimation: 20--23.5\% vs 20\%; extremum interval identification: 21--30\% vs 25\%). Fine-tuning substantially improves TOU (PNR up to 4.35), but TIU remains more challenging. This difficulty is not due to recognition deficits---models achieve 93.9\% on UCM classification. Cross-domain validation shows TIU transfers better than TOU (+8.0\% vs +3.9\%), suggesting that TIU, despite its lower baseline, has greater room for improvement. TimePerceptBench establishes a systematic framework for temporal reasoning over discrete observations.
\end{abstract}
